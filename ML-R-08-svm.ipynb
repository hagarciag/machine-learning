{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje de maquinas  -- R -- Máquinas de Soporte Vectorial.\n",
    "Notas de clase sobre aprendizaje de maquinas usando R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Juan David Velásquez Henao**   \n",
    "jdvelasq@unal.edu.co  \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia  \n",
    "\n",
    "[Licencia]\n",
    "\n",
    "[Readme]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Software utilizado**.\n",
    "\n",
    "> Este es un documento interactivo escrito como un notebook de [Jupyter](http://jupyter.org), en el cual se presenta un tutorial sobre regresión logistica usando **R** en el contexto de aprendizaje de maquinas. Los notebooks de Jupyter permiten incoporar simultáneamente código, texto, gráficos y ecuaciones. El código presentado en este notebook puede ejecutarse en los sistemas operativos Linux y OS X.\n",
    "\n",
    "> Haga click [aquí](https://github.com/jdvelasq/guias-de-instalacion) para obtener instrucciones detalladas sobre como instalar Jupyter en Windows y Mac OS X.\n",
    "\n",
    "> Haga clic [aquí] para ver la última versión de este documento en nbviewer.\n",
    "\n",
    "> Descargue la última versión de este documento a su disco duro; luego, carguelo y ejecutelo en línea en [Try Jupyter!](https://try.jupyter.org)\n",
    "\n",
    "> Haga clic [aquí](https://github.com/jdvelasq/ETVL-R/blob/master/ETVL-R-5-visualizacion-1-base.ipynb) para ver el tutorial de visualización y gráficas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">* [Introducción](#Introducción)\n",
    "* [Clasificación marginal máxima](#Clasificación-marginal-máxima)\n",
    "    * [Clasificación con Vectores de Soporte](#Clasificación-con-Vectores-de-Soporte)\n",
    "* [Kernels y Máquinas de Soporte Vectorial](#Kernels-y-Máquinas-de-Soporte-Vectorial)\n",
    "    * [Kernel Polinomico](#Kernel-Polinomico)\n",
    "    * [Kernel Radial](#Kernel-Radial)\n",
    "    * [Kernel Sigmoideo](#Kernel-Sigmoideo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bibliografía**.\n",
    "\n",
    ">  \n",
    "\n",
    "**Material complementario.**\n",
    "> Webinar RStudio [Getting your data into R](https://www.rstudio.com/resources/webinars/getting-your-data-into-r/) \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "Las _**máquinas de soporte vectorial (SVM)**_ son algoritmos no-lineales de aprendizaje supervisado utilizados para el problema de clasificación, no obstante se pueden utilizar para aproximar funciones o regresiones a partir de ciertos métodos. En esta sección se en clasificación. \n",
    "\n",
    "Básicamente, el algoritmo crea una frontera llamada _**hiperplano**_, la cual divide el espacio en particiones de las clases a predecir. En este sentido se puede considerar que las SVM combinan aspectos de los métodos de regresión y de vecinos más cercanos (k-NN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación marginal máxima\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "Uno de los conceptos más importantes en SVM, es el de **_Maximal Margin Classification_**, donde se asumirá que se tiene una variable respuesta binaria para ilustar. Dentro de los árboles de regresión y clasificación, usualmente la partición (hiperplanos de separación) del espacio de las variables es lineal. A diferencia de SVM donde dependiendo de la estructura, los supuestos y el criterio de optimización se puede terminar con uno de los infinitos hiperplanos (incluyendo no lineales) que pueden particionar los datos.\n",
    "\n",
    "Cuando se tiene dos o más variables predictoras, se expresar el hiperplano como una combinación lineal de dichas variables, por lo tanto:\n",
    "\n",
    "$$ \\beta_{0} + \\sum_{k=1}^{p} \\beta_{k} x_{i,k} > 0  \\hspace{0.25cm} si \\hspace{0.25cm} y_{i}=1 $$\n",
    "\n",
    "$$ \\beta_{0} + \\sum_{k=1}^{p} \\beta_{k} x_{i,k} < 0  \\hspace{0.25cm} si \\hspace{0.25cm} y_{i}=-1 $$\n",
    "\n",
    "Estas ecuaciones indican que cualquier punto que pertenezca a la clase 1, se encuentran por encima de la ecuación (mayor que 0). Análogmente, cualquier punto que pertenzca a la clase -1, se ubicará por debajo de ella (menor que 0). \n",
    "\n",
    "Ahora bien, para determinar cuál de todas las rectas utilizar para la separacion de datos, se define una cantidad denominada _**margen**_, la cual representa la mínima distancia perpendicular de cualquier punto de los datos al hiperplano. Para este ejemplo, siempre se tienen al menos dos (ya que son dos variables predictoras) que tengan la menor distancia al hiperplano. A veces, pueden existir puntos con iguales distancias mínimas.\n",
    "\n",
    "Lo anterior gráficamente es:\n",
    "\n",
    "<img src=\"images/SVM.png\" height=\"500\" width=\"500\">\n",
    "\n",
    "Por lo tanto, el _**hiperplano de maximo margen**_ como aquel cuyo margen sea el mayor posible de todos los hiperplanos posibles. Lo anterior definición busca el hiperplano que separará las clases de predicción mientras al mismo tiempo busca que este sea lo más alejado posible de las observaciones evitando así cualquier sesgo. En la imagen anterior, se observa que la linea es aquella con menor margen igual a 2, donde los tres vectores perpendiculares al hiperplano se llaman **_vectores de soporte_**.\n",
    "\n",
    "Para entender esto matemáticamente se define lo siguiente:\n",
    "\n",
    "$$ Seleccionar \\hspace{0.25cm} \\beta_{0},\\beta_{1},\\beta_{2},... \\hspace{0.25cm} que \\hspace{0.1cm} maximicen \\hspace{0.25cm} M $$\n",
    "$$ Tal \\hspace{0.1cm} que: \\hspace{0.25cm} \\sum_{k=1}^{p} \\beta_{k}^{2}=1 $$\n",
    "$$ además \\hspace{0.25cm} \\forall_{i}:y_{i} (\\beta_{0} + \\sum_{k=1}^{p} \\beta_{k} x_{i,k}) > M $$\n",
    "\n",
    "Las restricciones del problema establecen que deben ser correctamente clasificados los datos del problema así como que deben estar al menos de M unidades alejados del hiperplano, para esto se modifican los parámetros $ \\beta $ hasta encontrar el mayor **_M_** que cumpla las restricciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación con Vectores de Soporte\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "Cuando los datos de entranamiento no son lineamente clasificables se puede utilizar la definición de vectores de soporte para definir el margen, no obstante se permite que algunas observaciones estén mal clasificadas por el algoritmo, por lo tanto se estima un **_margen debil_**. Estas observaciones se permitiran estar dentro de un rango establecido y no afectaran la elección del hiperplano. \n",
    "\n",
    "Hay que tener en cuenta que entre más largo el margen es más confiable el hiperplano de clasificar las observaciones, es por esto que cuando los datos no son linealmente clasificables _\"relajar\"_ el margen puede ser beneficioso para el algortimo ya que evita que datos alejados modifiquen el hiperplano como se evidencia en la siguiente imagen donde se introdujo una observación de clase 1 cerca a los datos de clase -1 y el margen disminuyó de 2 a 0.29:\n",
    "\n",
    "<img src=\"images/SVM2.png\" height=\"500\" width=\"500\">\n",
    "\n",
    "Para esto, matematicamente, se ingresa un parametro de _\"suavizamiento\"_ $ \\xi $ tal que:\n",
    "\n",
    "$$ Seleccionar \\hspace{0.25cm} \\beta_{0},\\beta_{1},\\beta_{2},... \\hspace{0.25cm} que \\hspace{0.1cm} maximicen \\hspace{0.25cm} M $$\n",
    "$$ Tal \\hspace{0.1cm} que: \\hspace{0.25cm} \\sum_{k=1}^{p} \\beta_{k}^{2}=1 $$\n",
    "$$ además \\hspace{0.25cm} \\forall_{i}:y_{i} (\\beta_{0} + \\sum_{k=1}^{p} \\beta_{k} x_{i,k}) > M(1-\\xi_{i}) $$\n",
    "$$ además \\hspace{0.25cm} \\forall_{i}:\\xi_{i} > 0, \\sum_{i=1}^{n} \\xi_{i} <= C $$\n",
    "\n",
    "A las variables $ \\xi $ se les conocen como **_variables flojas_**, donde hay una para cada observacion y se cumple que:\n",
    "\n",
    "$$ \\xi_{i} = 0,  \\hspace{1cm} x_{i} \\hspace{0.1cm} está \\hspace{0.1cm} correctamente \\hspace{0.1cm} clasificada \\hspace{0.1cm} y \\hspace{0.1cm} fuera \\hspace{0.1cm} del \\hspace{0.1cm}margen $$\n",
    "$$ 0 < \\xi_{i} <= 1, \\hspace{0.6cm} x_{i} \\hspace{0.1cm} está \\hspace{0.1cm} correctamente \\hspace{0.1cm} clasificada \\hspace{0.1cm} pero \\hspace{0.1cm} dentro \\hspace{0.1cm} del \\hspace{0.1cm}margen $$\n",
    "$$ \\xi_{i} > 1, \\hspace{4cm} x_{i} \\hspace{0.1cm} está \\hspace{0.1cm} incorrectamente \\hspace{0.1cm} clasificada \\hspace{0.1cm} $$\n",
    "\n",
    "Donde la magnitud de la variable suelta es proporcional a la distancia entre la observación y el hiperplano.\n",
    "\n",
    "El hecho de que dichas variables no sobrepasen una cantidad C significa un límite superior de error en clasificación que estamos dispuestos a asumir. Si dicha constante C es baja (menor que 1) siginfica que el modelo tolerará pocas observaciones dentro del margen pero no permitirá errores de clasificación. Si por el contrario el valor de C es alto (mayor a 1) el modelo permitirá muchas observaciones dentro del margen o mal clasificadas, resultando en varios vectores de soporte. El primer escenario nos otorgará un modelo con mayor varianza pero menos sesgo, donde el último escenatio resultará en un modelo con menor varianza pero mayor sesgo. A esto se le conoce como el _**intercambio sesgo-varianza (Bias-Variance trade off)**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernels y Máquinas de Soporte Vectorial\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "Una forma de introducir la no-linealidad a las SVM es utilizar representaciones que involucren el concepto de producto interno de álgebra lineal para aplicar transformaciones no-lineales a su resultado. Para esto definimos una funcion general $ K $ que llamara la **_función núcleo (kernel)_** que opera en dos vectores y produce un resultado escalar. Esto se representa como:\n",
    "\n",
    "$$ y(x)=\\beta_{0}+\\sum_{s \\in S} \\alpha_{s} K \\langle x, x_{s} \\rangle $$\n",
    "\n",
    "El modelo de SVM tiene tantas características como vectores de soporte tenga y se definen estas características como un kernel aplicado a la observaciones con uno de los vectores de soporte. Para el ejemplo que anterior donde se evaluó un modelo lineal, se tiene que:\n",
    "\n",
    "$$ K_{lineal}(x_{i},x_{j}) = \\sum_{k=1}^{p} x_{i,k} x_{j,k} $$\n",
    "\n",
    "También estas funciones kernel puede medir la similaridad aplicando funciones que lo representen. Para introducir la no-linealidad simplemente se introducen los kernels no lineales y se crea las máquinas de soporte vectorial. Entre los kernels más usados están el polinómico y el de base radial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Polinomico\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "Esta función utiliza una expasión a la potencia del producto interno de dos vectores. Esencialmente este kernel transforma el espacio de las variables predictoras en uno de mayor grado, lo cual lo hace más eficiente comparado con transformar todas las características primero e intentar ajustar un modelo lineal en ese espacio.\n",
    "\n",
    "$$ K_{polinomico}(x_{i},x_{j}) = (1+\\sum_{k=1}^{p} x_{i,k} x_{j,k})^{d} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Radial\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "En este kernel el numero de dimensiones a la que se transforma el espacio de las variables predictoras es infinito dado al número infinito en la expansión. Si $ d \\approx \\infty $ entonces $ (1+\\frac{1}{d})^{d}=e $. Es por esto que este kernel no usa el producto interno, en su lugar usa la suma de la distnacia entre los dos vectores. Este kernel permite que solo los vectores de soporte cerca a la observación de interes interfieran significativamente en los cálculos. \n",
    "\n",
    "$$ K_{radial}(x_{i},x_{j}) = e^{-\\frac{1}{2\\sigma^{2}}\\sum_{k=1}^{p}(x_{i,k}- x_{j,k})^{2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Sigmoideo\n",
    "[Contenido](#Contenido)\n",
    "\n",
    "\n",
    "A diferencia de los anteriores, este kernel se asemeja a una red neuronal y utiliza la función de activación sigmoidea representada por la función tangente hiperbolica.\n",
    "\n",
    "$$ K_{sigmoideo}(x_{i},x_{j}) = tanh(\\kappa x_{i,k}\\cdot x_{j,k}-\\delta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Aplicación :\n",
    "En este ejemplo se utiliza la base de datos de creditos en Alemania la cual contiene las solicitudes de créditos que han realizado personas en un banco. La tarea del algoritmo es determinar si una solicitud contiene un alto riesgo de crédito para la entidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [`caret {caret}`](ftp://cran.r-project.org/pub/R/web/packages/caret/caret.pdf)\n",
    "\n",
    "> [`e1071 {e1071}`](https://cran.r-project.org/web/packages/e1071/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Instale y cargue las siguientes librerias\n",
    "library(caret)                                              \n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>checking</th><th scope=col>duration</th><th scope=col>creditHistory</th><th scope=col>purpose</th><th scope=col>credit</th><th scope=col>savings</th><th scope=col>employment</th><th scope=col>installmentRate</th><th scope=col>personal</th><th scope=col>debtors</th><th scope=col>...</th><th scope=col>property</th><th scope=col>age</th><th scope=col>otherPlans</th><th scope=col>housing</th><th scope=col>existingBankCredits</th><th scope=col>job</th><th scope=col>dependents</th><th scope=col>telephone</th><th scope=col>foreign</th><th scope=col>risk</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>A11 </td><td> 6  </td><td>A34 </td><td>A43 </td><td>1169</td><td>A65 </td><td>A75 </td><td>4   </td><td>A93 </td><td>A101</td><td>... </td><td>A121</td><td>67  </td><td>A143</td><td>A152</td><td>2   </td><td>A173</td><td>1   </td><td>A192</td><td>A201</td><td>1   </td></tr>\n",
       "\t<tr><td>A12 </td><td>48  </td><td>A32 </td><td>A43 </td><td>5951</td><td>A61 </td><td>A73 </td><td>2   </td><td>A92 </td><td>A101</td><td>... </td><td>A121</td><td>22  </td><td>A143</td><td>A152</td><td>1   </td><td>A173</td><td>1   </td><td>A191</td><td>A201</td><td>2   </td></tr>\n",
       "\t<tr><td>A14 </td><td>12  </td><td>A34 </td><td>A46 </td><td>2096</td><td>A61 </td><td>A74 </td><td>2   </td><td>A93 </td><td>A101</td><td>... </td><td>A121</td><td>49  </td><td>A143</td><td>A152</td><td>1   </td><td>A172</td><td>2   </td><td>A191</td><td>A201</td><td>1   </td></tr>\n",
       "\t<tr><td>A11 </td><td>42  </td><td>A32 </td><td>A42 </td><td>7882</td><td>A61 </td><td>A74 </td><td>2   </td><td>A93 </td><td>A103</td><td>... </td><td>A122</td><td>45  </td><td>A143</td><td>A153</td><td>1   </td><td>A173</td><td>2   </td><td>A191</td><td>A201</td><td>1   </td></tr>\n",
       "\t<tr><td>A11 </td><td>24  </td><td>A33 </td><td>A40 </td><td>4870</td><td>A61 </td><td>A73 </td><td>3   </td><td>A93 </td><td>A101</td><td>... </td><td>A124</td><td>53  </td><td>A143</td><td>A153</td><td>2   </td><td>A173</td><td>2   </td><td>A191</td><td>A201</td><td>2   </td></tr>\n",
       "\t<tr><td>A14 </td><td>36  </td><td>A32 </td><td>A46 </td><td>9055</td><td>A65 </td><td>A73 </td><td>2   </td><td>A93 </td><td>A101</td><td>... </td><td>A124</td><td>35  </td><td>A143</td><td>A153</td><td>1   </td><td>A172</td><td>2   </td><td>A192</td><td>A201</td><td>1   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       " checking & duration & creditHistory & purpose & credit & savings & employment & installmentRate & personal & debtors & ... & property & age & otherPlans & housing & existingBankCredits & job & dependents & telephone & foreign & risk\\\\\n",
       "\\hline\n",
       "\t A11  &  6   & A34  & A43  & 1169 & A65  & A75  & 4    & A93  & A101 & ...  & A121 & 67   & A143 & A152 & 2    & A173 & 1    & A192 & A201 & 1   \\\\\n",
       "\t A12  & 48   & A32  & A43  & 5951 & A61  & A73  & 2    & A92  & A101 & ...  & A121 & 22   & A143 & A152 & 1    & A173 & 1    & A191 & A201 & 2   \\\\\n",
       "\t A14  & 12   & A34  & A46  & 2096 & A61  & A74  & 2    & A93  & A101 & ...  & A121 & 49   & A143 & A152 & 1    & A172 & 2    & A191 & A201 & 1   \\\\\n",
       "\t A11  & 42   & A32  & A42  & 7882 & A61  & A74  & 2    & A93  & A103 & ...  & A122 & 45   & A143 & A153 & 1    & A173 & 2    & A191 & A201 & 1   \\\\\n",
       "\t A11  & 24   & A33  & A40  & 4870 & A61  & A73  & 3    & A93  & A101 & ...  & A124 & 53   & A143 & A153 & 2    & A173 & 2    & A191 & A201 & 2   \\\\\n",
       "\t A14  & 36   & A32  & A46  & 9055 & A65  & A73  & 2    & A93  & A101 & ...  & A124 & 35   & A143 & A153 & 1    & A172 & 2    & A192 & A201 & 1   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  checking duration creditHistory purpose credit savings employment\n",
       "1 A11       6       A34           A43     1169   A65     A75       \n",
       "2 A12      48       A32           A43     5951   A61     A73       \n",
       "3 A14      12       A34           A46     2096   A61     A74       \n",
       "4 A11      42       A32           A42     7882   A61     A74       \n",
       "5 A11      24       A33           A40     4870   A61     A73       \n",
       "6 A14      36       A32           A46     9055   A65     A73       \n",
       "  installmentRate personal debtors ... property age otherPlans housing\n",
       "1 4               A93      A101    ... A121     67  A143       A152   \n",
       "2 2               A92      A101    ... A121     22  A143       A152   \n",
       "3 2               A93      A101    ... A121     49  A143       A152   \n",
       "4 2               A93      A103    ... A122     45  A143       A153   \n",
       "5 3               A93      A101    ... A124     53  A143       A153   \n",
       "6 2               A93      A101    ... A124     35  A143       A153   \n",
       "  existingBankCredits job  dependents telephone foreign risk\n",
       "1 2                   A173 1          A192      A201    1   \n",
       "2 1                   A173 1          A191      A201    2   \n",
       "3 1                   A172 2          A191      A201    1   \n",
       "4 1                   A173 2          A191      A201    1   \n",
       "5 2                   A173 2          A191      A201    2   \n",
       "6 1                   A172 2          A192      A201    1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Lectura de datos\n",
    "link              <-\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"  \n",
    "\n",
    "german_raw        <- read.table(link,                                                     # Variable link\n",
    "                         quote = \"\\\"\")                                                    # Separador del encabezado\n",
    "\n",
    "names(german_raw) <- c( \"checking\", \"duration\", \"creditHistory\",                          # Titulos de las variables\n",
    "                        \"purpose\", \"credit\", \"savings\", \"employment\", \"installmentRate\",\n",
    "                        \"personal\", \"debtors\", \"presentResidence\", \"property\", \"age\",\n",
    "                        \"otherPlans\", \"housing\", \"existingBankCredits\", \"job\",\n",
    "                        \"dependents\", \"telephone\", \"foreign\", \"risk\")                        \n",
    "\n",
    "head(german_raw)                                                                          # Primeros datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que existen varias variables categoricas dentro de la base de datos, por lo cual se calculará y estimará variables dummys además de forzar la variable respuesta como 0 para buen crédito y 1 para mal crédito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>62</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 62\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 62\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>checking.A11</th><th scope=col>checking.A12</th><th scope=col>checking.A13</th><th scope=col>checking.A14</th><th scope=col>duration</th><th scope=col>creditHistory.A30</th><th scope=col>creditHistory.A31</th><th scope=col>creditHistory.A32</th><th scope=col>creditHistory.A33</th><th scope=col>creditHistory.A34</th><th scope=col>...</th><th scope=col>job.A171</th><th scope=col>job.A172</th><th scope=col>job.A173</th><th scope=col>job.A174</th><th scope=col>dependents</th><th scope=col>telephone.A191</th><th scope=col>telephone.A192</th><th scope=col>foreign.A201</th><th scope=col>foreign.A202</th><th scope=col>risk</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td> 6 </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>...</td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>1  </td><td>0  </td><td>1  </td><td>1  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>48 </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>1  </td><td>1  </td><td>0  </td><td>1  </td><td>0  </td><td>1  </td></tr>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>12 </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>...</td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>2  </td><td>1  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>42 </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>2  </td><td>1  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>24 </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>2  </td><td>1  </td><td>0  </td><td>1  </td><td>0  </td><td>1  </td></tr>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>36 </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>2  </td><td>0  </td><td>1  </td><td>1  </td><td>0  </td><td>0  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " checking.A11 & checking.A12 & checking.A13 & checking.A14 & duration & creditHistory.A30 & creditHistory.A31 & creditHistory.A32 & creditHistory.A33 & creditHistory.A34 & ... & job.A171 & job.A172 & job.A173 & job.A174 & dependents & telephone.A191 & telephone.A192 & foreign.A201 & foreign.A202 & risk\\\\\n",
       "\\hline\n",
       "\t 1   & 0   & 0   & 0   &  6  & 0   & 0   & 0   & 0   & 1   & ... & 0   & 0   & 1   & 0   & 1   & 0   & 1   & 1   & 0   & 0  \\\\\n",
       "\t 0   & 1   & 0   & 0   & 48  & 0   & 0   & 1   & 0   & 0   & ... & 0   & 0   & 1   & 0   & 1   & 1   & 0   & 1   & 0   & 1  \\\\\n",
       "\t 0   & 0   & 0   & 1   & 12  & 0   & 0   & 0   & 0   & 1   & ... & 0   & 1   & 0   & 0   & 2   & 1   & 0   & 1   & 0   & 0  \\\\\n",
       "\t 1   & 0   & 0   & 0   & 42  & 0   & 0   & 1   & 0   & 0   & ... & 0   & 0   & 1   & 0   & 2   & 1   & 0   & 1   & 0   & 0  \\\\\n",
       "\t 1   & 0   & 0   & 0   & 24  & 0   & 0   & 0   & 1   & 0   & ... & 0   & 0   & 1   & 0   & 2   & 1   & 0   & 1   & 0   & 1  \\\\\n",
       "\t 0   & 0   & 0   & 1   & 36  & 0   & 0   & 1   & 0   & 0   & ... & 0   & 1   & 0   & 0   & 2   & 0   & 1   & 1   & 0   & 0  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  checking.A11 checking.A12 checking.A13 checking.A14 duration\n",
       "1 1            0            0            0             6      \n",
       "2 0            1            0            0            48      \n",
       "3 0            0            0            1            12      \n",
       "4 1            0            0            0            42      \n",
       "5 1            0            0            0            24      \n",
       "6 0            0            0            1            36      \n",
       "  creditHistory.A30 creditHistory.A31 creditHistory.A32 creditHistory.A33\n",
       "1 0                 0                 0                 0                \n",
       "2 0                 0                 1                 0                \n",
       "3 0                 0                 0                 0                \n",
       "4 0                 0                 1                 0                \n",
       "5 0                 0                 0                 1                \n",
       "6 0                 0                 1                 0                \n",
       "  creditHistory.A34 ... job.A171 job.A172 job.A173 job.A174 dependents\n",
       "1 1                 ... 0        0        1        0        1         \n",
       "2 0                 ... 0        0        1        0        1         \n",
       "3 1                 ... 0        1        0        0        2         \n",
       "4 0                 ... 0        0        1        0        2         \n",
       "5 0                 ... 0        0        1        0        2         \n",
       "6 0                 ... 0        1        0        0        2         \n",
       "  telephone.A191 telephone.A192 foreign.A201 foreign.A202 risk\n",
       "1 0              1              1            0            0   \n",
       "2 1              0              1            0            1   \n",
       "3 1              0              1            0            0   \n",
       "4 1              0              1            0            0   \n",
       "5 1              0              1            0            1   \n",
       "6 0              1              1            0            0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Preparacion de los datos\n",
    "dummies <- dummyVars(risk ~ .,                               # Generar modelo para arrojar las variables dummy con risk de variable respuesta\n",
    "                     data = german_raw)                      # Base de datos\n",
    "\n",
    "german <- data.frame(predict(dummies, newdata = german_raw), # Generar la matriz con los dummy\n",
    "                     risk = factor((german_raw$risk - 1)))   # Generar la respuesta con el dummy 0 o 1\n",
    "\n",
    "dim(german)                                                  # Dimensiones de la matriz\n",
    "head(german)                                                 # Primeras filas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjunto de datos de entrenamiento y el de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): no se pudo encontrar la función \"createDataPartition\"\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): no se pudo encontrar la función \"createDataPartition\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "## Partición de la data\n",
    "set.seed(977)                                               # Semilla aleatoria\n",
    "\n",
    "german_sampling_vector <- createDataPartition(german$risk,  # Generar vector de posiciones de la partición\n",
    "                                              p = 0.80,     # Porcentaje de partición\n",
    "                                              list = FALSE) # Devuelve lista es falso\n",
    "\n",
    "german_train <- german[german_sampling_vector,]             # Datos de entrenamiento\n",
    "german_test <- german[-german_sampling_vector,]             # Datos de validacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que en este ejemplo el hecho que una empresa clasifique favorablemente a un cliente cuando esté se no cuenta con buen perfil credictio es cinco veces más costoso para la entidad ya que está dejando de colocar óptimamente. Para esto se define un vector de costo donde castigue más el error tipo II, es decir, clasificar como 1 al cliente, cuando en realidad es 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>0</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>5</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[0] 1\n",
       "\\item[1] 5\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "0\n",
       ":   11\n",
       ":   5\n",
       "\n"
      ],
      "text/plain": [
       "0 1 \n",
       "1 5 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Crear el vector de costos\n",
    "class_weights        <- c(1, 5)          # Vector de costos\n",
    "names(class_weights) <- c(\"0\", \"1\")      # Se les asigna nombre de la clase\n",
    "class_weights                            # Se observa el data.frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez creado el vector de costos, usando la función tune() para entrenar varios modelos svm() y encontrar el que tenga mejor desempeño con ciertos parámetros de búsqueda. Esta optimización arroja que los parámetros óptimos son costo igual a 10 y gamma igual a 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>cost</th><th scope=col>gamma</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>9</th><td>10  </td><td>0.05</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & cost & gamma\\\\\n",
       "\\hline\n",
       "\t9 & 10   & 0.05\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  cost gamma\n",
       "9 10   0.05 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.2675"
      ],
      "text/latex": [
       "0.2675"
      ],
      "text/markdown": [
       "0.2675"
      ],
      "text/plain": [
       "[1] 0.2675"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entrenar la SVM\n",
    "set.seed(2423)                                                                  # Semilla aleatoria\n",
    "\n",
    "german_radial_tune <- tune(svm,                                                 # Maquinas de soporte vectorial\n",
    "                           risk ~ .,                                            # Riesgo como variable dependiente\n",
    "                           data = german_train,                                 # Data de entrenamiento\n",
    "                           kernel = \"radial\",                                   # Tipo de Kernel = Radial\n",
    "                           ranges = list(cost = c(0.01, 0.1, 1, 10, 100),       # Valores de busqueda para el parámetro cost\n",
    "                                         gamma = c(0.01, 0.05, 0.1, 0.5, 1)),   # Valores de busqueda para el parámetro gamma\n",
    "                           class.weights = class_weights)                       # Vector de costos para los errores\n",
    "\n",
    "german_radial_tune$best.parameters                                              # Mejores parámetros del SVM\n",
    "\n",
    "german_radial_tune$best.performance                                             # Mejor métrica de desempeño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se extrae modelo final de la lista que devuelve la función tune(), se realizan las predicciones para comparar desempeño y hace la tabla cruzada de aciertos y errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.735"
      ],
      "text/latex": [
       "0.735"
      ],
      "text/markdown": [
       "0.735"
      ],
      "text/plain": [
       "[1] 0.735"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Modelo final\n",
    "german_model     <- german_radial_tune$best.model                  # Extraer el mejor modelo\n",
    "\n",
    "test_predictions <- predict(german_model,                          # Modelo SVM\n",
    "                            german_test[,1:61])                    # Data de validación\n",
    "\n",
    "mean(test_predictions == german_test[,62])                         # Ma media del acierto en las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         actual\n",
       "predicted   0   1\n",
       "        0 134  47\n",
       "        1   6  13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Tabla cruzada\n",
    "table(predicted = test_predictions,   # Predicciones\n",
    "      actual = german_test[,62])      # Verdaderos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Ejercicio.--** Utilice la base de datos de [_biodegradación QSAR_](https://archive.ics.uci.edu/ml/machine-learning-databases/00254/biodeg.csv) para predecir si un elemento en particular será biodegradable dadas sus características por ejemplo, cantidad de oxigeno, carbono, nitrogeno así como el numero de atomos pesados en la molecula. \n",
    "\n",
    "Utilice la librería **e1070** en R.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Libreria\n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [`kernlab {kernlab}`](https://cran.r-project.org/web/packages/kernlab/kernlab.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Instale y cargue las siguientes librerias\n",
    "library(kernlab)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente aplicación se tienen las 26 letras en mayuscula del alfabeto en inglés donde se incluyen letras script, cursivas, góticas y letras tipo tipografía (Serif). Se tiene una muestra de 20000 letras y la tarea de la SVM es determinar para cada una de ellas cuál es la letra correspondiente utilizando 16 características con atributos numéricos.\n",
    "\n",
    "<img src=\"images/img00.png\" height=500 width=300>\n",
    "\n",
    "Para clasificar se utilizó un espacio de 45x45 pixeles en los que se identificó los pixeles blancos (fondo de la imagen) y los negros (pixeles utilizados para crear el caracter) y los valores encontrados para cada característica se normalizaron en un rango de 0 a 15.\n",
    "\n",
    "\n",
    "Características utilizadas:\n",
    "\n",
    "1.  x.box: Posición horizontal, contando los pixeles desde el borde izquierdo de la imagen\n",
    "2.  y.box: Posición vertical, contando los pixeles desde el borde inferior de la imagen\n",
    "3.  Width: El ancho de los pixeles\n",
    "4.  High: El alto de los pixeles\n",
    "5.  onpix: El número total de pixeles negros\n",
    "6.  x.bar: La posición media horizontal de todos los pixeles negros con respecto al centro y dividido por el ancho del espacio\n",
    "7.  y.bar: La posición media vertical de todos los pixeles negros con respecto al centro y dividido por el alto del espacio\n",
    "8.  x2bar: El valor medio cuadrado de las distancias horizontales x.bar\n",
    "9.  y2bar: El valor medio cuadrado de las distancias verticales y.bar\n",
    "10. xybar: El producto medio de las distancias verticales y horizontales y.bar - x.bar\n",
    "11. x2ybr: Medida de correlación de la varianza de la distancia horizontal con respecto a la vertical (pixeles negros)\n",
    "12. xy2br: Medida de correlación de la varianza de la distancia vertical con respecto a la horizontal (pixeles negros)\n",
    "13. X.ege: El número promedio de bordes (pixeles negros junto a pixeles blancos) de izquierda a derecha para cada posición vertical del espacio\n",
    "14. xegvy: Suma de las posiciones verticales de los bordes encontrados en X.ege\n",
    "15. Y.ege: El número promedio de bordes encontrados de abajo a arriba para cada posición horizontal del espacio\n",
    "16. yegvx: Suma de las posiciones horizontales de los bordes encontrados en Y.ege\n",
    "\n",
    "\n",
    "Para objeto de estudio se dividió la muestra en entrenamiento y validación equivalente al 80% de los datos que se tomó para entrenar el algoritmo y el 20% restante utilizado para hacer las validaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'kernlab'\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    alpha\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t20000 obs. of  17 variables:\n",
      " $ letter: Factor w/ 26 levels \"A\",\"B\",\"C\",\"D\",..: 20 9 4 14 7 19 2 1 10 13 ...\n",
      " $ x.box : int  2 5 4 7 2 4 4 1 2 11 ...\n",
      " $ y.box : int  8 12 11 11 1 11 2 1 2 15 ...\n",
      " $ width : int  3 3 6 6 3 5 5 3 4 13 ...\n",
      " $ high  : int  5 7 8 6 1 8 4 2 4 9 ...\n",
      " $ onpix : int  1 2 6 3 1 3 4 1 2 7 ...\n",
      " $ x.bar : int  8 10 10 5 8 8 8 8 10 13 ...\n",
      " $ y.bar : int  13 5 6 9 6 8 7 2 6 2 ...\n",
      " $ x2bar : int  0 5 2 4 6 6 6 2 2 6 ...\n",
      " $ y2bar : int  6 4 6 6 6 9 6 2 6 2 ...\n",
      " $ xybar : int  6 13 10 4 6 5 7 8 12 12 ...\n",
      " $ x2ybr : int  10 3 3 4 5 6 6 2 4 1 ...\n",
      " $ xy2br : int  8 9 7 10 9 6 6 8 8 9 ...\n",
      " $ X.ege : int  0 2 3 6 1 0 2 1 1 8 ...\n",
      " $ xegvy : int  8 8 7 10 7 8 8 6 6 1 ...\n",
      " $ Y.ege : int  0 4 3 2 5 9 7 2 1 1 ...\n",
      " $ yegvx : int  8 10 9 8 10 7 10 7 7 8 ...\n"
     ]
    }
   ],
   "source": [
    "## Lectura datos \n",
    "\n",
    "letters <- read.csv(\"data.csv\")         # Lectura de la data\n",
    "\n",
    "str(letters)                            # Estructura de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Partición de los datos\n",
    "set.seed(1)                                                 # Semilla aleatoria\n",
    "\n",
    "trainIndex    <- createDataPartition(letters$letter,        # Generar vector de posiciones de la partición\n",
    "                                              p = 0.80,     # Porcentaje de partición\n",
    "                                              list = FALSE) # Devuelve lista es falso\n",
    "\n",
    "letters_train <- letters[trainIndex,]                       # Datos de entrenamiento\n",
    "letters_test  <- letters[-trainIndex,]                      # Datos de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Support Vector Machine object of class \"ksvm\" \n",
       "\n",
       "SV type: C-svc  (classification) \n",
       " parameter : cost C = 1 \n",
       "\n",
       "Linear (vanilla) kernel function. \n",
       "\n",
       "Number of Support Vectors : 7100 \n",
       "\n",
       "Objective Function Value : -15.6296 -24.1035 -32.6139 -6.9407 -11.2391 -33.8314 -61.6819 -19.9247 -66.8142 -34.664 -17.0182 -34.0862 -38.6445 -54.4292 -14.4757 -37.9456 -35.478 -16.676 -15.1289 -36.4191 -31.5295 -8.4011 -12.8527 -36.4246 -15.1811 -9.6631 -166.3312 -46.5484 -71.3353 -118.3936 -157.8402 -57.19 -43.1118 -76.2999 -26.5399 -20.3503 -22.4319 -36.8507 -44.8683 -122.0564 -198.2916 -203.692 -22.4506 -11.0084 -50.5033 -10.5674 -48.8043 -8.2428 -18.5451 -12.3587 -119.7663 -25.9019 -252.9595 -79.7413 -9.8543 -4.5354 -147.6783 -81.7189 -17.5327 -14.3599 -79.3617 -14.1883 -30.1773 -19.4426 -24.3816 -28.3644 -57.4585 -10.6397 -5.156 -14.0018 -4.6683 -4.5734 -7.8094 -39.5242 -52.733 -191.0638 -48.8511 -49.8955 -48.38 -17.3329 -17.9257 -87.0149 -113.984 -41.9839 -37.4487 -128.0483 -31.6999 -30.5003 -40.2004 -17.6703 -5.4254 -40.5818 -10.127 -19.5897 -61.457 -164.7185 -53.9735 -45.1218 -32.7226 -78.4436 -128.7579 -7.7926 -4.4973 -13.0046 -28.0001 -144.3059 -52.6895 -185.1087 -101.1071 -10.2861 -15.4408 -3.0366 -70.9248 -8.4659 -96.7448 -51.9271 -97.0994 -72.4081 -66.078 -25.2059 -13.516 -7.7437 -27.2402 -14.3216 -231.8682 -32.0182 -22.9489 -117.0789 -127.9985 -10.6071 -36.2559 -6.661 -55.0129 -61.5703 -32.367 -222.5596 -33.9807 -17.1567 -135.9669 -162.8287 -37.1961 -23.0355 -136.2965 -79.2474 -358.5877 -139.8925 -158.2267 -36.7762 -31.6717 -54.6171 -23.7241 -47.2747 -6.5682 -9.6633 -31.2075 -59.5595 -200.2849 -53.1097 -76.7927 -149.1051 -608.9825 -120.1413 -139.2066 -322.6822 -33.3301 -68.2861 -168.2828 -109.8055 -36.4133 -65.0367 -48.9212 -8.2925 -211.6559 -13.3675 -40.3996 -1.6783 -6.4708 -15.7039 -24.2792 -63.3143 -20.6278 -181.5077 -21.7433 -4.8287 -4.4453 -0.8414 -121.2993 -9.2322 -72.8311 -19.4974 -12.4608 -4.1944 -15.6757 -26.735 -20.5946 -75.2172 -24.842 -95.7836 -14.3627 -10.3159 -6.1829 -1.8683 -82.2801 -7.4171 -107.8906 -111.06 -36.6146 -23.5303 -60.0458 -21.498 -56.0182 -268.3554 -44.4758 -49.8371 -34.6814 -20.3505 -9.3535 -119.9536 -6.3201 -5.918 -9.3876 -12.1083 -22.369 -20.5086 -147.5779 -36.481 -95.2062 -30.2022 -15.2242 -10.528 -3.6662 -101.3321 -7.4074 -14.2149 -66.5613 -90.5667 -12.1291 -11.1699 -46.3752 -2.1586 -6.5785 -72.8206 -32.0065 -118.0653 -3.5576 -7.1291 -1.0498 -93.0395 -20.0544 -9.466 -46.5849 -3.183 -17.4104 -69.1557 -43.2736 -56.1116 -5.2805 -20.35 -2.2441 -72.1423 -114.873 -105.8891 -22.6937 -18.9277 -59.5579 -38.4504 -65.6126 -19.5407 -5.8265 -3.8988 -59.7491 -33.3004 -52.2709 -30.6458 -9.654 -46.3303 -10.3099 -19.1255 -64.0671 -4.8174 -65.0977 -230.4235 -16.5851 -12.409 -17.5244 -7.3137 -67.7321 -14.6215 -40.225 -50.1392 -28.3776 -16.4511 -42.4395 -15.3091 -56.8525 -4.7905 -6.1346 -75.1794 -3.3871 -6.694 -1.1129 -134.6156 -26.0153 -372.5829 -30.8361 -29.3164 -4.5656 -77.3432 -132.6668 -77.2841 -26.5899 -39.3386 -10.9058 -24.4309 -1.9996 -60.0088 -7.7833 -158.8157 -1.8546 -1.8262 -10.7389 -0.5096 -29.2206 -32.8548 -6.1986 \n",
       "Training error : 0.131776 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entrenamiento del modelo SVM \n",
    "\n",
    "letter_classifier <- ksvm(letter ~ .,              # Variable respuesta es la letra\n",
    "                          data = letters_train,    # Datos de entrenamiento\n",
    "                          kernel = \"vanilladot\")   # Tipo de kernel lineal\n",
    "\n",
    "letter_classifier                                  # Visualizamos el svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.859327983951856"
      ],
      "text/latex": [
       "0.859327983951856"
      ],
      "text/markdown": [
       "0.859327983951856"
      ],
      "text/plain": [
       "[1] 0.859328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Predicción y evaluacion con el modelo\n",
    "\n",
    "letter_predictions <- predict(letter_classifier,      # Clasificador SVM\n",
    "                              letters_test)           # Datos de validación\n",
    "\n",
    "mean(letter_predictions == letters_test$letter)       # Media de los aciertos del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  \n",
       "letter_predictions   A   B   C   D   E   F   G   H   I   J   K   L   M   N   O\n",
       "                 A 149   2   0   1   0   0   0   0   0   2   0   0   1   2   5\n",
       "                 B   0 139   0   3   0   1   0   2   1   0   0   1   4   0   0\n",
       "                 C   0   0 133   0   1   1   6   1   0   0   1   0   0   0   2\n",
       "                 D   0   0   0 150   0   1   5  11   3   1   1   2   0   4   4\n",
       "                 E   0   2   3   0 138   2   0   0   0   0   2   6   0   0   0\n",
       "                 F   0   0   0   1   0 135   0   2   3   1   0   0   0   1   0\n",
       "                 G   0   1   3   0   5   0 122   1   0   0   4   4   0   0   1\n",
       "                 H   0   3   0   1   1   0   1  98   0   1   1   1   0   3  13\n",
       "                 I   0   0   0   0   0   0   0   0 131   8   0   0   0   0   0\n",
       "                 J   2   0   0   0   0   0   0   4   1 130   0   0   0   0   0\n",
       "                 K   1   0   5   0   1   1   2   8   0   0 126   0   0   1   0\n",
       "                 L   1   0   0   0   0   0   1   1   0   0   0 131   0   0   0\n",
       "                 M   1   0   0   0   0   0   3   0   0   0   0   0 142   1   0\n",
       "                 N   0   0   0   2   0   0   0   1   0   1   0   0   0 139   0\n",
       "                 O   0   0   2   2   0   0   0   5   0   0   0   0   2   2 115\n",
       "                 P   0   1   0   0   0   4   0   0   0   0   0   0   0   1   1\n",
       "                 Q   0   0   0   0   2   0   2   1   0   0   0   4   0   0   1\n",
       "                 R   0   4   0   1   1   0   3   8   0   0   6   0   4   1   2\n",
       "                 S   1   0   0   0   1   5   5   0   8   5   1   2   0   0   0\n",
       "                 T   0   0   1   0   0   5   0   0   0   0   0   0   0   0   1\n",
       "                 U   0   0   0   0   0   0   1   2   0   0   0   0   2   0   1\n",
       "                 V   0   1   0   0   0   0   2   1   0   0   0   0   0   0   0\n",
       "                 W   0   0   0   0   0   0   1   0   0   0   1   0   3   1   4\n",
       "                 X   0   0   0   0   2   0   0   0   2   0   4   1   0   0   0\n",
       "                 Y   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "                 Z   0   0   0   0   1   0   0   0   2   0   0   0   0   0   0\n",
       "                  \n",
       "letter_predictions   P   Q   R   S   T   U   V   W   X   Y   Z\n",
       "                 A   0   6   4   2   0   1   1   1   0   0   0\n",
       "                 B   0   2   2   9   0   0   4   0   1   0   0\n",
       "                 C   0   0   0   0   0   1   0   0   0   0   0\n",
       "                 D   0   1   1   0   1   0   0   0   0   0   1\n",
       "                 E   2   1   0   5   2   0   0   0   3   0   0\n",
       "                 F  12   0   0  10   1   0   0   0   1   3   1\n",
       "                 G   2   3   1   3   1   0   0   0   1   0   0\n",
       "                 H   1   0   2   0   2   2   2   1   1   1   0\n",
       "                 I   0   0   0   6   0   0   0   0   5   0   0\n",
       "                 J   1   1   0   0   0   0   0   0   0   0   4\n",
       "                 K   3   0   7   0   0   0   0   0   6   0   0\n",
       "                 L   0   0   1   3   0   0   0   0   3   0   1\n",
       "                 M   0   0   0   0   0   5   0   1   0   0   0\n",
       "                 N   0   0   4   0   0   0   0   1   0   0   0\n",
       "                 O   4   2   3   0   0   1   0   0   1   0   0\n",
       "                 P 134   0   0   1   2   0   1   0   0   1   0\n",
       "                 Q   0 127   0   3   0   0   0   0   0   3   2\n",
       "                 R   0   0 124   2   0   0   0   0   2   0   0\n",
       "                 S   0  11   0  98   4   0   0   0   0   0  13\n",
       "                 T   0   0   1   1 139   0   0   0   1   4   0\n",
       "                 U   0   0   0   0   1 150   0   0   2   0   0\n",
       "                 V   1   1   0   0   0   0 135   1   0   2   0\n",
       "                 W   0   1   1   0   0   2   5 145   0   0   0\n",
       "                 X   0   0   0   0   0   0   0   0 130   0   0\n",
       "                 Y   0   0   0   1   3   0   4   0   0 143   0\n",
       "                 Z   0   0   0   5   3   0   0   0   0   0 124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tabla cruzada\n",
    "\n",
    "table(letter_predictions,    # Predicciones\n",
    "      letters_test$letter)   # Reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aciertos\n",
       "FALSE  TRUE \n",
       "  561  3427 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "aciertos\n",
       "   FALSE     TRUE \n",
       "0.140672 0.859328 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculo de aciertos y  errores\n",
    "\n",
    "aciertos <- letter_predictions == letters_test$letter    # Vector de comparacion lógica\n",
    "\n",
    "table(aciertos)                                          # Mostrar tabla de aciertos\n",
    "\n",
    "prop.table(table(aciertos))                              # Mostrar tabla de aciertos en porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aciertosEV\n",
       "FALSE  TRUE \n",
       "  253  3735 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "aciertosEV\n",
       "     FALSE       TRUE \n",
       "0.06344032 0.93655968 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Realización del mismo modelo pero con base radial y comparación de resultados\n",
    "\n",
    "letter_classifierEV  <- ksvm(letter ~ ., data = letters_train,kernel = \"rbfdot\")\n",
    "letter_predictionsEV <- predict(letter_classifierEV, letters_test)\n",
    "aciertosEV           <- letter_predictionsEV == letters_test$letter\n",
    "\n",
    "table(aciertosEV)\n",
    "prop.table(table(aciertosEV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "aciertosEV2\n",
       "FALSE  TRUE \n",
       " 3634   354 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "aciertosEV2\n",
       "    FALSE      TRUE \n",
       "0.9112337 0.0887663 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Realización del mismo modelo pero con base sigmoidea y comparacion resultados\n",
    "\n",
    "letter_classifierEV2  <- ksvm(letter ~ ., data = letters_train,kernel = \"tanhdot\")\n",
    "letter_predictionsEV2 <- predict(letter_classifierEV2, letters_test)\n",
    "aciertosEV2           <- letter_predictionsEV2 == letters_test$letter\n",
    "\n",
    "table(aciertosEV2)\n",
    "prop.table(table(aciertosEV2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Ejercicio.--** Se busca identificar si la voz transmitida por una persona es de hombre o mujer, el conjunto de datos tiene analisis y caracteristicas de onda que tiene la voz transmitida. Utilice las caracteristicas deel siguiente conjunto de datos para realizar la predicción si es hombre o mujer  \n",
    "\n",
    "[Datos](https://drive.google.com/file/d/0B4psHlllKLPUTFNTM242MGhlM2s/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
